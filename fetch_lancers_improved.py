#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import aiohttp
import json
import re
import os
import openpyxl
from pathlib import Path
from typing import List
from openpyxl.utils import get_column_letter
from datetime import datetime
from playwright.async_api import async_playwright

# ====== ç’°å¢ƒè¨­å®š ======
EXCEL_PATH = r"C:\Users\SUZUKI Natsumi\æ ªå¼ä¼šç¤¾ReySolid\ã€Bã€‘IT-Solution@ReySolid - æ¡ˆä»¶ç®¡ç† - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\æ¡ˆä»¶ç®¡ç†\æ¡ˆä»¶æƒ…å ±.xlsx"
LANCERS_SEARCH_URL = "https://www.lancers.jp/work/search/system?budget_from=&budget_to=&work_rank%5B%5D=&work_rank%5B%5D=&work_rank%5B%5D=&keyword=&sort=work_post_date"
MAX_JOBS_TO_FETCH = 100
HEADLESS_MODE = True

# ã¾ãŸã¯å‹•çš„ã«é¸æŠ
def get_excel_path():
    paths = [
        r"C:\Users\SUZUKI Natsumi\æ ªå¼ä¼šç¤¾ReySolid\ã€Bã€‘IT-Solution@ReySolid - æ¡ˆä»¶ç®¡ç† - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\æ¡ˆä»¶ç®¡ç†\æ¡ˆä»¶æƒ…å ±.xlsx",
        r"C:\Users\SUZUKI Natsumi\OneDrive - æ ªå¼ä¼šç¤¾ReySolid\æ¡ˆä»¶æƒ…å ±.xlsx"
    ]
    
    for path in paths:
        if os.path.exists(path):
            print(f"ğŸ“Š ä½¿ç”¨ã™ã‚‹Excelãƒ•ã‚¡ã‚¤ãƒ«: {path}")
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’è¡¨ç¤º
            mtime = datetime.fromtimestamp(os.path.getmtime(path))
            print(f"   æœ€çµ‚æ›´æ–°: {mtime}")
            return path
    
    return paths[0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

EXCEL_PATH = get_excel_path()


# å¼Šç¤¾ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆï¼ˆæ¤œç´¢ãƒ¯ãƒ¼ãƒ‰å„ªå…ˆç‰ˆï¼‰
COMPANY_SKILLS = {
    "è¶…é«˜å„ªå…ˆåº¦": ["AI", "GPT", "ChatGPT", "Python", "API", "Django", "Next.js","React","TypeScript", "æ©Ÿæ¢°å­¦ç¿’"],
    "é«˜å„ªå…ˆåº¦": ["bot", "Talend", "Java", "ã‚¹ãƒãƒ›ã‚¢ãƒ—ãƒª", "ãƒ¢ãƒã‚¤ãƒ«é–‹ç™º", "äººå·¥çŸ¥èƒ½"],
    "ä¸­å„ªå…ˆåº¦": ["åŠ¹ç‡åŒ–", "ãƒ„ãƒ¼ãƒ«", "é–‹ç™º", "ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º", "React", "Node.js", "è‡ªå‹•åŒ–", "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"],
    "ä½å„ªå…ˆåº¦": ["PostgreSQL", "MySQL", "ç¤¾å†…ãƒ„ãƒ¼ãƒ«", "æ¥­å‹™æ”¹å–„", "ã‚¢ãƒ—ãƒª", "ã‚µã‚¤ãƒˆ", "ç®¡ç†"],
    "æœ€ä½å„ªå…ˆåº¦": ["Render", "ãƒ­ãƒªãƒƒãƒãƒƒãƒ—", "WordPress", "PHP"]
}

# é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
EXCLUDE_KEYWORDS = [
    "æ±‚äºº", "æ¡ç”¨", "è»¢è·", "æ­£ç¤¾å“¡", "ã‚¢ãƒ«ãƒã‚¤ãƒˆ", "æ´¾é£",
    "ã‚³ãƒ³ãƒš", "ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³", "ã‚³ãƒ³ãƒ†ã‚¹ãƒˆ",
    "å‹Ÿé›†çµ‚äº†", "çµ‚äº†", "ç· åˆ‡", "CAD",
    'ãƒ‡ã‚¶ã‚¤ãƒ³', 'ã‚¤ãƒ©ã‚¹ãƒˆ', 'ãƒ­ã‚´', 'å‹•ç”»ç·¨é›†', 'å†™çœŸ', 'æ’®å½±', 'Photoshop',
    'Illustrator', 'After Effects', 'Premiere', 'ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯', 'UI/UX',
    'XD', 'Sketch', 'Canva', 'ãƒãƒŠãƒ¼', 'ãƒãƒ©ã‚·', 'ãƒã‚¹ã‚¿ãƒ¼',
    'æ±‚äºº', 'æ¡ç”¨', 'ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ', 'ã‚¹ã‚«ã‚¦ãƒˆ', 'äººæ', 'ã‚³ãƒ³ãƒš', 'ã‚³ãƒ³ãƒ†ã‚¹ãƒˆ',
    'æ‡¸è³', 'å¿œå‹Ÿè€…å¤šæ•°', 'é¸è€ƒ', 'å¯©æŸ»', 'ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°', 'è¨˜äº‹ä½œæˆ', 'ã‚²ãƒ¼ãƒ ',
    'ãƒ–ãƒ­ã‚°è¨˜äº‹', 'SEOè¨˜äº‹', 'ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°', 'ã‚·ãƒŠãƒªã‚ª', 'è„šæœ¬',
    'ç¿»è¨³', 'é€šè¨³', 'ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆ', 'ãƒ¢ãƒ‹ã‚¿ãƒ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼',
    'ãƒ†ãƒ¬ã‚¢ãƒ', 'å–¶æ¥­', 'ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆ', 'ã‚µãƒãƒ¼ãƒˆæ¥­å‹™', 'äº‹å‹™',
    'çµŒç†', 'ç§˜æ›¸', 'ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ', 'å†…è·', 'ç°¡å˜ä½œæ¥­', 'è»½ä½œæ¥­'

]

# ====== Excel ãƒ˜ãƒ«ãƒ‘ï¼ˆã‚¯ãƒ©ã‚¹å¤–ï¼‰ ======
def _format_skill_matches_compact_for_excel(skill_matches: List[dict]) -> str:
    if not skill_matches:
        return ""
    ultra = [m.get("skill") for m in skill_matches if m.get("priority") == "è¶…é«˜å„ªå…ˆåº¦"]
    high  = [m.get("skill") for m in skill_matches if m.get("priority") == "é«˜å„ªå…ˆåº¦"]
    mid   = [m.get("skill") for m in skill_matches if m.get("priority") == "ä¸­å„ªå…ˆåº¦"]
    low   = [m.get("skill") for m in skill_matches if m.get("priority") == "ä½å„ªå…ˆåº¦"]
    lowst = [m.get("skill") for m in skill_matches if m.get("priority") == "æœ€ä½å„ªå…ˆåº¦"]
    parts = []
    if ultra: parts.append("ğŸ”¥" + ",".join(ultra[:2]))
    if high:  parts.append("â˜…" + ",".join(high[:2]))
    if mid:   parts.append("â—†" + ",".join(mid[:2]))
    if low:   parts.append("â—‡" + ",".join(low[:1]))
    if lowst: parts.append("â—‹" + ",".join(lowst[:1]))
    s = " ".join(parts)
    return (s[:97] + "...") if len(s) > 100 else s

def _autosize_columns(ws):
    for col in ws.columns:
        max_len = 0
        col_letter = get_column_letter(col[0].column)
        for cell in col:
            v = str(cell.value) if cell.value is not None else ""
            max_len = max(max_len, len(v))
        ws.column_dimensions[col_letter].width = min(max(12, max_len + 2), 60)

def _ensure_book_and_sheets(path: Path):
    if not path.exists():
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "ãƒ©ãƒ³ã‚µãƒ¼ã‚º"
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ˜ãƒƒãƒ€ãƒ¼æ§‹æˆã«å¤‰æ›´
        ws.append([
            "å–å¾—æ—¥æ™‚",
            "ã‚¿ã‚¤ãƒˆãƒ«", 
            "ã‚«ãƒ†ã‚´ãƒª",
            "ä¾¡æ ¼",
            "ç· åˆ‡",
            "URL",
            "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢",
            "ã‚¹ã‚­ãƒ«æ¦‚è¦"
        ])
        stat = wb.create_sheet("çµ±è¨ˆ")
        stat.append(["timestamp","count","type","skill_match_rate","no_skill_match","multi_skill_match","high_priority"])
        wb.save(path)
    else:
        wb = openpyxl.load_workbook(path)
        if "ãƒ©ãƒ³ã‚µãƒ¼ã‚º" not in wb.sheetnames:
            ws = wb.create_sheet("ãƒ©ãƒ³ã‚µãƒ¼ã‚º")
            ws.append([
                "å–å¾—æ—¥æ™‚",
                "ã‚¿ã‚¤ãƒˆãƒ«",
                "ã‚«ãƒ†ã‚´ãƒª", 
                "ä¾¡æ ¼",
                "ç· åˆ‡",
                "URL",
                "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢",
                "ã‚¹ã‚­ãƒ«æ¦‚è¦"
            ])
        if "çµ±è¨ˆ" not in wb.sheetnames:
            stat = wb.create_sheet("çµ±è¨ˆ")
            stat.append(["timestamp","count","type","skill_match_rate","no_skill_match","multi_skill_match","high_priority"])
    return wb

def append_jobs_to_excel(data: dict, excel_path: str = EXCEL_PATH, dedupe_by_url: bool = True):
    try:
        path = Path(excel_path)
        wb = _ensure_book_and_sheets(path)
        ws = wb["ãƒ©ãƒ³ã‚µãƒ¼ã‚º"]
        stat = wb["çµ±è¨ˆ"]

        existing_urls = set()
        if dedupe_by_url:
            for row in ws.iter_rows(min_row=2, values_only=True):
                if row and len(row) >= 6 and row[5]:  # URLåˆ—ã¯6ç•ªç›®
                    existing_urls.add(row[5])

        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        new_rows = 0
        
        for job in data.get("jobs", []):
            url = job.get("link") or ""
            if dedupe_by_url and url in existing_urls:
                continue
                
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã¨åŒã˜é †åºã§è¿½è¨˜
            ws.append([
                now_str,                    # å–å¾—æ—¥æ™‚
                job.get("title",""),        # ã‚¿ã‚¤ãƒˆãƒ«
                job.get("category",""),     # ã‚«ãƒ†ã‚´ãƒªãƒ¼
                job.get("price",""),        # ä¾¡æ ¼
                job.get("deadline",""),     # ç· åˆ‡
                url,                        # URL
                job.get("priority_score",""), # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢
                _format_skill_matches_compact_for_excel(job.get("skill_matches", []))  # ã‚¹ã‚­ãƒ«æ¦‚è¦
            ])
            
            last = ws.max_row
            # URLã«ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯è¨­å®šï¼ˆ6åˆ—ç›®ï¼‰
            if url:
                ws.cell(row=last, column=6).hyperlink = url
                ws.cell(row=last, column=6).style = "Hyperlink"
            
            new_rows += 1

        # çµ±è¨ˆã‚·ãƒ¼ãƒˆã®æ›´æ–°
        dist = data.get("skill_distribution", {})
        stat.append([
            data.get("timestamp", now_str),
            data.get("count", 0),
            data.get("type", ""),
            dist.get("skill_match_rate",""),
            dist.get("no_skill_match",""),
            dist.get("multi_skill_match",""),
            dist.get("high_priority",""),
        ])

        _autosize_columns(ws)
        _autosize_columns(stat)
        wb.save(path)
        print(f"ğŸ“Š Excelå‡ºåŠ›: {path} | æ¡ˆä»¶ {new_rows}ä»¶ã‚’è¿½è¨˜ï¼ˆçµ±è¨ˆ1è¡Œï¼‰")
        
    except PermissionError:
        print("âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‹ã‹ã‚Œã¦ã„ã¾ã™ã€‚é–‰ã˜ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        print(f"âŒ Excelå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")

class CompleteJobsNotifier:
    def __init__(self):
        self.jobs_data = []
        self.seen_links = set()

    async def fetch_jobs(self):
        """å…¨æ¡ˆä»¶ã‚’å–å¾—ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æœ€å°é™ï¼‰"""
        print("ğŸš€ Lancerså…¨æ¡ˆä»¶å–å¾—ã‚’é–‹å§‹...")

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=HEADLESS_MODE, slow_mo=300)
            try:
                context = await browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                    locale="ja-JP"
                )
                page = await context.new_page()

                print(f"ğŸ“¡ ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {LANCERS_SEARCH_URL}")
                response = await page.goto(LANCERS_SEARCH_URL, wait_until="domcontentloaded", timeout=60000)
                print(f"âœ… ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å®Œäº† (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status})")

                await page.wait_for_timeout(5000)
                await self.scroll_and_load_more(page)

                job_elements = await page.query_selector_all("a[href*='/work/detail/']")
                print(f"ğŸ“Š {len(job_elements)} å€‹ã®æ¡ˆä»¶å€™è£œã‚’ç™ºè¦‹")

                all_jobs = []
                for element in job_elements:
                    if len(all_jobs) >= MAX_JOBS_TO_FETCH:
                        break
                    job_info = await self.extract_job_info(element, page)
                    if job_info and self.should_include_job_minimal(job_info):
                        all_jobs.append(job_info)
                        skill_info = self.format_skill_matches(job_info["skill_matches"])
                        print(f"ğŸ“ æ¡ˆä»¶ {len(all_jobs)}: {job_info['title'][:40]}... | {skill_info}")

                sorted_jobs = self.sort_by_skill_relevance(all_jobs)
                print(f"âœ… å…¨ {len(sorted_jobs)} ä»¶ã®æ¡ˆä»¶ã‚’å–å¾—ã—ã¾ã—ãŸ")
                self.jobs_data = sorted_jobs
                return sorted_jobs

            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                return []
            finally:
                await browser.close()

    async def scroll_and_load_more(self, page):
        try:
            for _ in range(5):
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await page.wait_for_timeout(2000)
            more_button = await page.query_selector(".more-button, .load-more, [class*='more']")
            if more_button:
                await more_button.click()
                await page.wait_for_timeout(3000)
            for _ in range(3):
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await page.wait_for_timeout(2000)
        except Exception as e:
            print(f"âš ï¸ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    async def extract_job_info(self, element, page):
        try:
            title_text = await element.text_content()
            href = await element.get_attribute("href")
            if not title_text or not href:
                return None
            title = self.clean_title(title_text)
            if not title or len(title) < 5:
                return None
            if href.startswith("/"):
                href = "https://www.lancers.jp" + href
            if href in self.seen_links:
                return None
            self.seen_links.add(href)

            recruitment_info = await self.extract_recruitment_details(element)
            skill_matches = self.find_all_skill_matches(title)
            job_info = {
                "title": title,
                "link": href,
                "price": recruitment_info["price"],
                "deadline": recruitment_info["deadline"],
                "applicant_count": recruitment_info["applicant_count"],
                "recruitment_count": recruitment_info["recruitment_count"],
                "client_name": recruitment_info["client_name"],
                "status": recruitment_info["status"],
                "urgency": recruitment_info["urgency"],
                "category": recruitment_info["category"],
                "skill_matches": skill_matches,
                "skill_count": len(skill_matches),
                "priority_score": self.calculate_comprehensive_score(title, recruitment_info, skill_matches),
                "scraped_at": datetime.now().isoformat()
            }
            return job_info
        except Exception as e:
            print(f"âš ï¸ æ¡ˆä»¶æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def find_all_skill_matches(self, title):
        matches = []
        title_lower = title.lower()
        for priority, skills in COMPANY_SKILLS.items():
            for skill in skills:
                if skill.lower() in title_lower:
                    matches.append({"skill": skill, "priority": priority})
        additional_keywords = {
            "è‡ªå‹•åŒ–": "ä¸­å„ªå…ˆåº¦",
            "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°": "ä¸­å„ªå…ˆåº¦", 
            "ã‚¢ãƒ—ãƒª": "ä¸­å„ªå…ˆåº¦",
            "ã‚µã‚¤ãƒˆ": "ä½å„ªå…ˆåº¦",
            "ç®¡ç†": "ä½å„ªå…ˆåº¦",
            "ã‚³ãƒ³ã‚µãƒ«": "ä¸­å„ªå…ˆåº¦",
            "Ai": "è¶…é«˜å„ªå…ˆåº¦",
            "äººå·¥çŸ¥èƒ½": "é«˜å„ªå…ˆåº¦"
        }
        for keyword, priority in additional_keywords.items():
            if keyword.lower() in title_lower:
                matches.append({"skill": keyword, "priority": priority})
        seen_skills = set()
        unique_matches = []
        for m in matches:
            if m["skill"] not in seen_skills:
                unique_matches.append(m)
                seen_skills.add(m["skill"])
        return unique_matches

    def format_skill_matches(self, skill_matches):
        if not skill_matches:
            return "ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: ãªã—"
        skills_by_priority = {}
        for m in skill_matches:
            p = m["priority"]
            skills_by_priority.setdefault(p, []).append(m["skill"])
        parts = []
        if "è¶…é«˜å„ªå…ˆåº¦" in skills_by_priority: parts.append(f"ğŸ”¥{', '.join(skills_by_priority['è¶…é«˜å„ªå…ˆåº¦'])}")
        if "é«˜å„ªå…ˆåº¦" in skills_by_priority:  parts.append(f"â˜…{', '.join(skills_by_priority['é«˜å„ªå…ˆåº¦'])}")
        if "ä¸­å„ªå…ˆåº¦" in skills_by_priority:  parts.append(f"â—†{', '.join(skills_by_priority['ä¸­å„ªå…ˆåº¦'])}")
        if "ä½å„ªå…ˆåº¦" in skills_by_priority:  parts.append(f"â—‡{', '.join(skills_by_priority['ä½å„ªå…ˆåº¦'])}")
        if "æœ€ä½å„ªå…ˆåº¦" in skills_by_priority: parts.append(f"â—‹{', '.join(skills_by_priority['æœ€ä½å„ªå…ˆåº¦'])}")
        return f"ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: {' | '.join(parts)}" if parts else "ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: ãªã—"

    def format_skill_matches_compact(self, skill_matches: List[dict]) -> str:
        if not skill_matches:
            return "ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: ãªã—"
        ultra = [m.get("skill") for m in skill_matches if m.get("priority") == "è¶…é«˜å„ªå…ˆåº¦"]
        high  = [m.get("skill") for m in skill_matches if m.get("priority") == "é«˜å„ªå…ˆåº¦"]
        mid   = [m.get("skill") for m in skill_matches if m.get("priority") == "ä¸­å„ªå…ˆåº¦"]
        low   = [m.get("skill") for m in skill_matches if m.get("priority") == "ä½å„ªå…ˆåº¦"]
        lowst = [m.get("skill") for m in skill_matches if m.get("priority") == "æœ€ä½å„ªå…ˆåº¦"]
        parts = []
        if ultra: parts.append("ğŸ”¥" + ",".join(ultra[:2]))
        if high:  parts.append("â˜…" + ",".join(high[:2]))
        if mid:   parts.append("â—†" + ",".join(mid[:2]))
        if low:   parts.append("â—‡" + ",".join(low[:1]))
        if lowst: parts.append("â—‹" + ",".join(lowst[:1]))
        s = " ".join(parts) if parts else ""
        if len(s) > 100: s = s[:97] + "..."
        return f"ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: {s}" if s else "ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: ãªã—"

    async def extract_recruitment_details(self, element):
        recruitment_info = {
            "price": "ä¾¡æ ¼æƒ…å ±ãªã—",
            "deadline": "æœŸé™æƒ…å ±ãªã—", 
            "applicant_count": "0",
            "recruitment_count": "1",
            "client_name": "ä¾é ¼è€…æƒ…å ±ãªã—",
            "status": "å‹Ÿé›†ä¸­",
            "urgency": False,
            "category": "ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º"
        }
        try:
            parent = await element.evaluate_handle("el => el.closest('.c-media, .p-jobList__item, article, li')")
            if parent:
                price_elem = await parent.query_selector(".c-media__price, .price, .budget, [class*='price']")
                if price_elem:
                    price_text = await price_elem.text_content()
                    if price_text and "å††" in price_text:
                        recruitment_info["price"] = self.clean_price_text(price_text)
                deadline_elem = await parent.query_selector(".c-media__deadline, .deadline, [class*='deadline']")
                if deadline_elem:
                    deadline_text = await deadline_elem.text_content()
                    if deadline_text:
                        recruitment_info["deadline"] = deadline_text.strip()
                        if any(w in deadline_text for w in ["æ€¥å‹Ÿ", "ç·Šæ€¥", "å³æ—¥", "è‡³æ€¥"]):
                            recruitment_info["urgency"] = True
                applicant_elem = await parent.query_selector(".c-media__applicant, .applicant, [class*='applicant']")
                if applicant_elem:
                    applicant_text = await applicant_elem.text_content()
                    if applicant_text:
                        numbers = re.findall(r'(\d+)', applicant_text)
                        if len(numbers) >= 2:
                            recruitment_info["applicant_count"] = numbers[0]
                            recruitment_info["recruitment_count"] = numbers[1]
        except:
            pass
        return recruitment_info

    def clean_title(self, title):
        if not title:
            return ""
        try:
            import unicodedata
            title = unicodedata.normalize('NFKC', title)
        except:
            pass
        title = re.sub(r'\s+', ' ', title.strip())
        title = re.sub(r'^(NEW\s*){1,}', '', title, flags=re.IGNORECASE)
        title = re.sub(r'^\d+å›ç›®\s*', '', title)
        return title.strip()

    def clean_price_text(self, raw_price):
        if not raw_price:
            return "ä¾¡æ ¼æƒ…å ±ãªã—"
        try:
            import unicodedata
            raw_price = unicodedata.normalize('NFKC', raw_price)
        except:
            pass
        price = re.sub(r'\s+', ' ', raw_price.strip())
        price = re.sub(r'å††\s*/\s*', 'å†† / ', price)
        return price

    def calculate_comprehensive_score(self, title, recruitment_info, skill_matches):
        score = 0
        title_lower = title.lower()
        for m in skill_matches:
            p = m["priority"]
            if p == "è¶…é«˜å„ªå…ˆåº¦": score += 100
            elif p == "é«˜å„ªå…ˆåº¦": score += 50
            elif p == "ä¸­å„ªå…ˆåº¦": score += 20
            elif p == "ä½å„ªå…ˆåº¦": score += 10
            elif p == "æœ€ä½å„ªå…ˆåº¦": score += 5
        if len(skill_matches) >= 3: score += 50
        elif len(skill_matches) >= 2: score += 25
        elif len(skill_matches) >= 1: score += 10
        priority_keywords = {
            "chatgpt": 80, "python": 70, "api": 60, "ai": 60,
            "è‡ªå‹•åŒ–": 40, "bot": 40, "åŠ¹ç‡åŒ–": 30, "ãƒ„ãƒ¼ãƒ«": 25, "é–‹ç™º": 20, "ã‚·ã‚¹ãƒ†ãƒ ": 15
        }
        for k, bonus in priority_keywords.items():
            if k in title_lower:
                score += bonus
        if recruitment_info["urgency"]:
            score += 15
        try:
            applicant_count = int(recruitment_info["applicant_count"])
            if applicant_count == 0: score += 10
            elif applicant_count <= 2: score += 5
        except:
            pass
        price_text = recruitment_info["price"]
        if "å††" in price_text:
            numbers = re.findall(r'(\d+,?\d*)', price_text.replace(',', ''))
            if numbers:
                try:
                    max_price = max([int(num.replace(',', '')) for num in numbers])
                    if max_price >= 500000: score += 15
                    elif max_price >= 100000: score += 8
                    elif max_price >= 50000:  score += 3
                except:
                    pass
        return score

    def should_include_job_minimal(self, job_info):
        title = job_info["title"]
        if not title or len(title.strip()) < 5:
            return False
        title_lower = title.lower()
        for keyword in EXCLUDE_KEYWORDS:
            if keyword.lower() in title_lower:
                return False
        status = job_info["status"]
        if any(w in status for w in ["å‹Ÿé›†çµ‚äº†", "ç· åˆ‡", "çµ‚äº†", "å®Œäº†"]):
            return False
        if job_info["priority_score"] >= 10 or job_info["skill_count"] >= 1:
            return True
        priority_keywords = ["chatgpt", "python", "api", "ai", "è‡ªå‹•åŒ–", "bot", "åŠ¹ç‡åŒ–", "ãƒ„ãƒ¼ãƒ«", "é–‹ç™º", "ã‚·ã‚¹ãƒ†ãƒ "]
        if any(k in title_lower for k in priority_keywords):
            return True
        return False

    def sort_by_skill_relevance(self, jobs):
        def sort_key(job):
            base_score = job["priority_score"]
            if job["skill_count"] == 0:
                base_score -= 1000
            applicant_count = int(job["applicant_count"]) if job["applicant_count"].isdigit() else 999
            return (-base_score, -job["skill_count"], applicant_count, not job["urgency"], job["scraped_at"])
        return sorted(jobs, key=sort_key)

    def create_teams_payload(self, jobs):
        if not jobs:
            return {
                "@type": "MessageCard",
                "@context": "https://schema.org/extensions",
                "summary": "Lancerså…¨æ¡ˆä»¶é€šçŸ¥",
                "themeColor": "0078D4",
                "title": "ğŸš€ Lancerså…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆ",
                "text": "ğŸ“­ ç¾åœ¨æ¡ä»¶ã«åˆã†æ¡ˆä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            }
        MAX_CHARS = 25000
        header_text = f"ç¾åœ¨ã®å…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆã§ã™ï¼ˆ**{len(jobs)}ä»¶**ã‚’ç™ºè¦‹ï¼‰\n\n"
        footer_text = "\n\nğŸ“‹ è©³ç´°æƒ…å ±ã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚ç¢ºèªã§ãã¾ã™ã€‚"
        available_chars = MAX_CHARS - len(header_text) - len(footer_text) - 500
        main_content = ""
        displayed_count = 0
        skipped_count = 0
        print(f"ğŸ“Š Teamsè¡¨ç¤ºåˆ¶é™: {MAX_CHARS:,}æ–‡å­—ã¾ã§åˆ©ç”¨å¯èƒ½")
        for i, job in enumerate(jobs, 1):
            skill_info = self.format_skill_matches_compact(job["skill_matches"])
            job_text  = f"**{i}. {job['title']}**  \n"
            job_text += f"ğŸ’° {job['price']}  \n"
            if job['deadline'] != "æœŸé™æƒ…å ±ãªã—" and len(job['deadline']) < 20:
                job_text += f"â° {job['deadline']}  \n"
            if job['applicant_count'] != "0":
                job_text += f"ğŸ‘¥ å¿œå‹Ÿ{job['applicant_count']}äºº  \n"
            job_text += f"{skill_info}  \n"
            if job['urgency']:
                job_text += f"ğŸš¨ æ€¥å‹Ÿ  \n"
            job_text += f"ğŸ”— [è©³ç´°]({job['link']})  \n\n"
            if len(main_content) + len(job_text) > available_chars:
                skipped_count = len(jobs) - displayed_count
                print(f"ğŸ“ æ–‡å­—æ•°åˆ¶é™ã«ã‚ˆã‚Š {displayed_count}ä»¶è¡¨ç¤ºã€{skipped_count}ä»¶ã‚¹ã‚­ãƒƒãƒ—")
                break
            main_content += job_text
            displayed_count += 1
        final_text = header_text + main_content + (f"\nğŸ“‹ æ®‹ã‚Š{skipped_count}ä»¶ã®æ¡ˆä»¶ã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã§ç¢ºèªã§ãã¾ã™ã€‚" if skipped_count > 0 else footer_text)
        actual_chars = len(final_text)
        print(f"ğŸ“Š å®Ÿéš›ã®æ–‡å­—æ•°: {actual_chars:,}æ–‡å­— / {MAX_CHARS:,}æ–‡å­— ({actual_chars/MAX_CHARS*100:.1f}%)")
        print(f"ğŸ“Š è¡¨ç¤ºæ¡ˆä»¶æ•°: {displayed_count}ä»¶ / {len(jobs)}ä»¶")
        return {
            "@type": "MessageCard",
            "@context": "https://schema.org/extensions",
            "summary": f"Lancerså…¨æ¡ˆä»¶ {len(jobs)}ä»¶",
            "themeColor": "0078D4",
            "title": f"ğŸš€ Lancerså…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆ ({len(jobs)}ä»¶ç™ºè¦‹ / {displayed_count}ä»¶è¡¨ç¤º) - {datetime.now().strftime('%Y/%m/%d %H:%M')}",
            "text": final_text,
            "potentialAction": [{
                "@type": "OpenUri",
                "name": "ğŸ” Lancersã§æ¡ˆä»¶ã‚’æ¢ã™",
                "targets": [{"os": "default", "uri": LANCERS_SEARCH_URL}]
            }]
        }

    async def send_to_teams(self, jobs):
        try:
            from dotenv import load_dotenv
            load_dotenv()
        except:
            pass
        webhook_url = os.getenv("TEAMS_WEBHOOK_URL")
        if not webhook_url:
            print("âŒ Teams Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False

        payload = self.create_teams_payload(jobs)

        try:
            async with aiohttp.ClientSession() as session:
                print("ğŸ“¤ Teamsã«å…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
                async with session.post(
                    webhook_url,
                    json=payload,
                    headers={"Content-Type": "application/json"}
                ) as response:
                    if response.status == 200:
                        print("âœ… Teamsé€ä¿¡æˆåŠŸï¼")
                        return True
                    else:
                        print(f"âŒ Teamsé€ä¿¡å¤±æ•— (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status})")
                        return False
        except Exception as e:
            print(f"âŒ Teamsé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def save_data(self, jobs):
        timestamp = datetime.now()
        data = {
            "timestamp": timestamp.isoformat(),
            "count": len(jobs),
            "type": "å…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆ",
            "skill_summary": self.create_skill_summary(jobs),
            "skill_distribution": self.create_skill_distribution(jobs),
            "jobs": jobs
        }
        filename = f"all_jobs_{timestamp.strftime('%Y%m%d_%H%M')}.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å…¨æ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {filename}")

    def create_skill_summary(self, jobs):
        skill_counts = {}
        for job in jobs:
            for match in job["skill_matches"]:
                skill = match["skill"]
                skill_counts[skill] = skill_counts.get(skill, 0) + 1
        return dict(sorted(skill_counts.items(), key=lambda x: x[1], reverse=True))

    def create_skill_distribution(self, jobs):
        total_jobs = len(jobs)
        no_skill_jobs = len([job for job in jobs if job["skill_count"] == 0])
        multi_skill_jobs = len([job for job in jobs if job["skill_count"] >= 2])
        high_priority_jobs = len([job for job in jobs if job["priority_score"] >= 10])
        return {
            "total_jobs": total_jobs,
            "no_skill_match": no_skill_jobs,
            "multi_skill_match": multi_skill_jobs,
            "high_priority": high_priority_jobs,
            "skill_match_rate": round((total_jobs - no_skill_jobs) / total_jobs * 100, 1) if total_jobs > 0 else 0
        }


# ====== ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ ======
async def main():
    print("=" * 70)
    print("ğŸ¤– Lancerså…¨æ¡ˆä»¶å–å¾—ã‚·ã‚¹ãƒ†ãƒ ï¼ˆTeams28KBæœ€å¤§æ´»ç”¨ç‰ˆï¼‰")
    print("=" * 70)

    notifier = CompleteJobsNotifier()
    jobs = await notifier.fetch_jobs()

    if jobs:
        # JSONä¿å­˜
        notifier.save_data(jobs)

        # Excelã«ã‚‚è¿½è¨˜
        excel_data = {
            "timestamp": datetime.now().isoformat(),
            "count": len(jobs),
            "type": "å…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆ",
            "skill_summary": notifier.create_skill_summary(jobs),
            "skill_distribution": notifier.create_skill_distribution(jobs),
            "jobs": jobs
        }
        append_jobs_to_excel(excel_data, EXCEL_PATH, dedupe_by_url=True)

        # Teamsé€ä¿¡
        teams_success = await notifier.send_to_teams(jobs)

        print("\n" + "=" * 70)
        print("ğŸ“Š å®Ÿè¡Œçµæœ:")
        print("=" * 70)
        print(f"âœ… å…¨æ¡ˆä»¶æ•°: {len(jobs)}ä»¶")
        print(f"ğŸ“¤ Teamsé€ä¿¡: {'æˆåŠŸ' if teams_success else 'å¤±æ•—'}")
        print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜: å®Œäº†")

        skill_summary = notifier.create_skill_summary(jobs)
        skill_distribution = notifier.create_skill_distribution(jobs)
        print(f"\nğŸ”§ ã‚¹ã‚­ãƒ«åˆ¥ãƒãƒƒãƒä»¶æ•°ï¼ˆä¸Šä½10ä½ï¼‰:")
        for skill, count in list(skill_summary.items())[:10]:
            print(f"   {skill}: {count}ä»¶")

        print(f"\nğŸ“ˆ ã‚¹ã‚­ãƒ«åˆ†å¸ƒ:")
        print(f"   ã‚¹ã‚­ãƒ«ãƒãƒƒãƒç‡: {skill_distribution['skill_match_rate']}%")
        print(f"   è¤‡æ•°ã‚¹ã‚­ãƒ«ãƒãƒƒãƒ: {skill_distribution['multi_skill_match']}ä»¶")
        print(f"   é«˜å„ªå…ˆåº¦æ¡ˆä»¶: {skill_distribution['high_priority']}ä»¶")
        print(f"   ã‚¹ã‚­ãƒ«ãƒãƒƒãƒãªã—: {skill_distribution['no_skill_match']}ä»¶")
    else:
        print("âŒ æ¡ˆä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

if __name__ == "__main__":
    asyncio.run(main())
