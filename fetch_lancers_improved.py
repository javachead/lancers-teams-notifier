#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import aiohttp
import json
import re
import os
import openpyxl
from pathlib import Path
from typing import List
from openpyxl.utils import get_column_letter
from datetime import datetime, timedelta
from playwright.async_api import async_playwright

# =============================
# ç’°å¢ƒåˆ¤å®š
# =============================
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

# =============================
# è¨­å®šå€¤
# =============================
LANCERS_SEARCH_URL = "https://www.lancers.jp/work/search/system?budget_from=&budget_to=&work_rank%5B%5D=&work_rank%5B%5D=&work_rank%5B%5D=&keyword=&sort=work_post_date"
MAX_JOBS_TO_FETCH = 100
HEADLESS_MODE = os.getenv("HEADLESS", "true").lower() != "false"  # ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯

# =============================
# ä¿å­˜å…ˆï¼ˆç’°å¢ƒã«ã‚ˆã‚Šåˆ‡æ›¿ï¼‰ï¼‹ä¸Šæ›¸ãå¯¾å¿œ
# =============================
def _ensure_parent_dir(p: str):
    try:
        Path(p).parent.mkdir(parents=True, exist_ok=True)
    except Exception:
        pass

def get_excel_path_local() -> str:
    paths = [
        r"C:\Users\SUZUKI Natsumi\æ ªå¼ä¼šç¤¾ReySolid\ã€Bã€‘IT-Solution@ReySolid - æ¡ˆä»¶ç®¡ç† - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\æ¡ˆä»¶ç®¡ç†\æ¡ˆä»¶æƒ…å ±.xlsx",
        r"C:\Users\SUZUKI Natsumi\OneDrive - æ ªå¼ä¼šç¤¾ReySolid\æ¡ˆä»¶æƒ…å ±.xlsx",
    ]
    for path in paths:
        if os.path.exists(path):
            print(f"ğŸ“Š ä½¿ç”¨ã™ã‚‹Excelãƒ•ã‚¡ã‚¤ãƒ«: {path}")
            try:
                mtime = datetime.fromtimestamp(os.path.getmtime(path))
                print(f"   æœ€çµ‚æ›´æ–°: {mtime}")
            except Exception:
                pass
            return path
    # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã‚‚ç¬¬1å€™è£œã‚’è¿”ã—ã€å¾Œç¶šã§è‡ªå‹•ä½œæˆ
    _ensure_parent_dir(paths[0])
    return paths[0]

# å„ªå…ˆåº¦: ç’°å¢ƒå¤‰æ•° EXCEL_PATH > è‡ªå‹•åˆ¤å®š
env_override = os.getenv("EXCEL_PATH")

if IS_GITHUB_ACTIONS:
    EXCEL_PATH = env_override or "æ¡ˆä»¶æƒ…å ±.xlsx"  # Actions ã¯ãƒªãƒã‚¸ãƒˆãƒªç›´ä¸‹
    print("ğŸ“ GitHub Actionsç’°å¢ƒã§å®Ÿè¡Œä¸­: Excelã¯ãƒªãƒã‚¸ãƒˆãƒªã«ä¿å­˜ã—ã¾ã™")
else:
    EXCEL_PATH = env_override or get_excel_path_local()
    print("ğŸ“ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œä¸­: OneDrive/SharePoint ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™")

print(f"ğŸ“„ EXCEL_PATH = {EXCEL_PATH}")

# =============================
# ã‚¹ã‚­ãƒ«è¨­å®š / é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
# =============================
COMPANY_SKILLS = {
    "è¶…é«˜å„ªå…ˆåº¦": ["AI", "GPT", "ChatGPT", "Python", "API", "Django", "Next.js","React","TypeScript", "æ©Ÿæ¢°å­¦ç¿’"],
    "é«˜å„ªå…ˆåº¦": ["bot", "Talend", "Java", "ã‚¹ãƒãƒ›ã‚¢ãƒ—ãƒª", "ãƒ¢ãƒã‚¤ãƒ«é–‹ç™º", "äººå·¥çŸ¥èƒ½"],
    "ä¸­å„ªå…ˆåº¦": ["åŠ¹ç‡åŒ–", "ãƒ„ãƒ¼ãƒ«", "é–‹ç™º", "ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º", "React", "Node.js", "è‡ªå‹•åŒ–", "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"],
    "ä½å„ªå…ˆåº¦": ["PostgreSQL", "MySQL", "ç¤¾å†…ãƒ„ãƒ¼ãƒ«", "æ¥­å‹™æ”¹å–„", "ã‚¢ãƒ—ãƒª", "ã‚µã‚¤ãƒˆ", "ç®¡ç†"],
    "æœ€ä½å„ªå…ˆåº¦": ["Render", "ãƒ­ãƒªãƒƒãƒãƒƒãƒ—", "WordPress", "PHP"]
}

EXCLUDE_KEYWORDS = [
    "æ±‚äºº", "æ¡ç”¨", "è»¢è·", "æ­£ç¤¾å“¡", "ã‚¢ãƒ«ãƒã‚¤ãƒˆ", "æ´¾é£",
    "ã‚³ãƒ³ãƒš", "ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³", "ã‚³ãƒ³ãƒ†ã‚¹ãƒˆ",
    "å‹Ÿé›†çµ‚äº†", "çµ‚äº†", "ç· åˆ‡", "CAD",
    'ãƒ‡ã‚¶ã‚¤ãƒ³', 'ã‚¤ãƒ©ã‚¹ãƒˆ', 'ãƒ­ã‚´', 'å‹•ç”»ç·¨é›†', 'å†™çœŸ', 'æ’®å½±', 'Photoshop',
    'Illustrator', 'After Effects', 'Premiere', 'ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯', 'UI/UX',
    'XD', 'Sketch', 'Canva', 'ãƒãƒŠãƒ¼', 'ãƒãƒ©ã‚·', 'ãƒã‚¹ã‚¿ãƒ¼',
    'æ±‚äºº', 'æ¡ç”¨', 'ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ', 'ã‚¹ã‚«ã‚¦ãƒˆ', 'äººæ', 'ã‚³ãƒ³ãƒš', 'ã‚³ãƒ³ãƒ†ã‚¹ãƒˆ',
    'æ‡¸è³', 'å¿œå‹Ÿè€…å¤šæ•°', 'é¸è€ƒ', 'å¯©æŸ»', 'ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°', 'è¨˜äº‹ä½œæˆ', 'ã‚²ãƒ¼ãƒ ',
    'ãƒ–ãƒ­ã‚°è¨˜äº‹', 'SEOè¨˜äº‹', 'ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°', 'ã‚·ãƒŠãƒªã‚ª', 'è„šæœ¬',
    'ç¿»è¨³', 'é€šè¨³', 'ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆ', 'ãƒ¢ãƒ‹ã‚¿ãƒ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼',
    'ãƒ†ãƒ¬ã‚¢ãƒ', 'å–¶æ¥­', 'ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆ', 'ã‚µãƒãƒ¼ãƒˆæ¥­å‹™', 'äº‹å‹™',
    'çµŒç†', 'ç§˜æ›¸', 'ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ', 'å†…è·', 'ç°¡å˜ä½œæ¥­', 'è»½ä½œæ¥­'
]

# =============================
# Excel ãƒ˜ãƒ«ãƒ‘
# =============================
def _format_skill_matches_compact_for_excel(skill_matches: List[dict]) -> str:
    if not skill_matches:
        return ""
    ultra = [m.get("skill") for m in skill_matches if m.get("priority") == "è¶…é«˜å„ªå…ˆåº¦"]
    high  = [m.get("skill") for m in skill_matches if m.get("priority") == "é«˜å„ªå…ˆåº¦"]
    mid   = [m.get("skill") for m in skill_matches if m.get("priority") == "ä¸­å„ªå…ˆåº¦"]
    low   = [m.get("skill") for m in skill_matches if m.get("priority") == "ä½å„ªå…ˆåº¦"]
    lowst = [m.get("skill") for m in skill_matches if m.get("priority") == "æœ€ä½å„ªå…ˆåº¦"]
    parts = []
    if ultra: parts.append("ğŸ”¥" + ",".join(ultra[:2]))
    if high:  parts.append("â˜…" + ",".join(high[:2]))
    if mid:   parts.append("â—†" + ",".join(mid[:2]))
    if low:   parts.append("â—‡" + ",".join(low[:1]))
    if lowst: parts.append("â—‹" + ",".join(lowst[:1]))
    s = " ".join(parts)
    return (s[:97] + "...") if len(s) > 100 else s

def _autosize_columns(ws):
    for col in ws.columns:
        max_len = 0
        col_letter = get_column_letter(col[0].column)
        for cell in col:
            v = str(cell.value) if cell.value is not None else ""
            max_len = max(max_len, len(v))
        ws.column_dimensions[col_letter].width = min(max(12, max_len + 2), 60)

def _ensure_book_and_sheets(path: Path):
    if not path.exists():
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "ãƒ©ãƒ³ã‚µãƒ¼ã‚º"
        ws.append(["å–å¾—æ—¥æ™‚","ã‚¿ã‚¤ãƒˆãƒ«","ã‚«ãƒ†ã‚´ãƒª","ä¾¡æ ¼","ç· åˆ‡","URL","å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢","ã‚¹ã‚­ãƒ«æ¦‚è¦"])
        stat = wb.create_sheet("çµ±è¨ˆ")
        stat.append(["timestamp","count","type","skill_match_rate","no_skill_match","multi_skill_match","high_priority"])
        wb.save(path)
    else:
        wb = openpyxl.load_workbook(path)
        if "ãƒ©ãƒ³ã‚µãƒ¼ã‚º" not in wb.sheetnames:
            ws = wb.create_sheet("ãƒ©ãƒ³ã‚µãƒ¼ã‚º")
            ws.append(["å–å¾—æ—¥æ™‚","ã‚¿ã‚¤ãƒˆãƒ«","ã‚«ãƒ†ã‚´ãƒª","ä¾¡æ ¼","ç· åˆ‡","URL","å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢","ã‚¹ã‚­ãƒ«æ¦‚è¦"])
        if "çµ±è¨ˆ" not in wb.sheetnames:
            stat = wb.create_sheet("çµ±è¨ˆ")
            stat.append(["timestamp","count","type","skill_match_rate","no_skill_match","multi_skill_match","high_priority"])
    return wb

def replace_lancers_sheet(data: dict, excel_path: str = EXCEL_PATH):
    try:
        path = Path(excel_path)
        wb = _ensure_book_and_sheets(path)

        if "ãƒ©ãƒ³ã‚µãƒ¼ã‚º" in wb.sheetnames:
            del wb["ãƒ©ãƒ³ã‚µãƒ¼ã‚º"]

        ws = wb.create_sheet("ãƒ©ãƒ³ã‚µãƒ¼ã‚º", 0)
        ws.append(["å–å¾—æ—¥æ™‚","ã‚¿ã‚¤ãƒˆãƒ«","ã‚«ãƒ†ã‚´ãƒª","ä¾¡æ ¼","ç· åˆ‡","URL","å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢","ã‚¹ã‚­ãƒ«æ¦‚è¦"])

        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        for job in data.get("jobs", []):
            url = job.get("link", "")
            ws.append([
                now_str,
                job.get("title", ""),
                job.get("category", ""),
                job.get("price", ""),
                job.get("deadline", ""),
                url,
                job.get("priority_score", ""),
                _format_skill_matches_compact_for_excel(job.get("skill_matches", []))
            ])
            last = ws.max_row
            if url:
                ws.cell(row=last, column=6).hyperlink = url
                ws.cell(row=last, column=6).style = "Hyperlink"

        _autosize_columns(ws)
        wb.save(path)
        print(f"âœ… ã€ãƒ©ãƒ³ã‚µãƒ¼ã‚ºã€ã‚·ãƒ¼ãƒˆã‚’ä¸Šæ›¸ãä¿å­˜ã—ã¾ã—ãŸ: {excel_path}")

    except Exception as e:
        print(f"âŒ ãƒ©ãƒ³ã‚µãƒ¼ã‚ºä¸Šæ›¸ãã‚¨ãƒ©ãƒ¼: {e}")


# =============================
# å–å¾—ãƒ»é€šçŸ¥ã‚¯ãƒ©ã‚¹
# =============================
class CompleteJobsNotifier:
    def __init__(self):
        self.jobs_data = []
        self.seen_links = set()

    async def fetch_jobs(self):
        print("ğŸš€ Lancerså…¨æ¡ˆä»¶å–å¾—ã‚’é–‹å§‹...")
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=HEADLESS_MODE, slow_mo=300)
            try:
                context = await browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                    locale="ja-JP"
                )
                page = await context.new_page()
                print(f"ğŸ“¡ ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {LANCERS_SEARCH_URL}")
                response = await page.goto(LANCERS_SEARCH_URL, wait_until="domcontentloaded", timeout=60000)
                print(f"âœ… ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å®Œäº† (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status})")

                await page.wait_for_timeout(5000)
                await self.scroll_and_load_more(page)

                job_elements = await page.query_selector_all("a[href*='/work/detail/']")
                print(f"ğŸ“Š {len(job_elements)} å€‹ã®æ¡ˆä»¶å€™è£œã‚’ç™ºè¦‹")

                all_jobs = []
                for element in job_elements[:MAX_JOBS_TO_FETCH]:
                    job_info = await self.extract_job_info(element, page)
                    if job_info and self.should_include_job_minimal(job_info):
                        all_jobs.append(job_info)
                        skill_info = self.format_skill_matches(job_info["skill_matches"])
                        print(f"ğŸ“ æ¡ˆä»¶ {len(all_jobs)}: {job_info['title'][:40]}... | {skill_info}")

                sorted_jobs = self.sort_by_skill_relevance(all_jobs)
                print(f"âœ… å…¨ {len(sorted_jobs)} ä»¶ã®æ¡ˆä»¶ã‚’å–å¾—ã—ã¾ã—ãŸ")
                self.jobs_data = sorted_jobs
                return sorted_jobs

            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                return []
            finally:
                await browser.close()

    async def scroll_and_load_more(self, page):
        try:
            for _ in range(5):
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await page.wait_for_timeout(2000)
            more_button = await page.query_selector(".more-button, .load-more, [class*='more']")
            if more_button:
                await more_button.click()
                await page.wait_for_timeout(3000)
            for _ in range(3):
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await page.wait_for_timeout(2000)
        except Exception as e:
            print(f"âš ï¸ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    async def extract_job_info(self, element, page):
        try:
            title_text = await element.text_content()
            href = await element.get_attribute("href")
            if not title_text or not href:
                return None
            title = self.clean_title(title_text)
            if not title or len(title) < 5:
                return None
            if href.startswith("/"):
                href = "https://www.lancers.jp" + href
            if href in self.seen_links:
                return None
            self.seen_links.add(href)

            recruitment_info = await self.extract_recruitment_details(element)
            skill_matches = self.find_all_skill_matches(title)
            job_info = {
                "title": title,
                "link": href,
                "price": recruitment_info["price"],
                "deadline": recruitment_info["deadline"],
                "applicant_count": recruitment_info["applicant_count"],
                "recruitment_count": recruitment_info["recruitment_count"],
                "client_name": recruitment_info["client_name"],
                "status": recruitment_info["status"],
                "urgency": recruitment_info["urgency"],
                "category": recruitment_info["category"],
                "skill_matches": skill_matches,
                "skill_count": len(skill_matches),
                "priority_score": self.calculate_comprehensive_score(title, recruitment_info, skill_matches),
                "scraped_at": datetime.now().isoformat()
            }
            return job_info
        except Exception as e:
            print(f"âš ï¸ æ¡ˆä»¶æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def find_all_skill_matches(self, title):
        matches = []
        title_lower = title.lower()
        for priority, skills in COMPANY_SKILLS.items():
            for skill in skills:
                if skill.lower() in title_lower:
                    matches.append({"skill": skill, "priority": priority})
        additional_keywords = {
            "è‡ªå‹•åŒ–": "ä¸­å„ªå…ˆåº¦",
            "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°": "ä¸­å„ªå…ˆåº¦",
            "ã‚¢ãƒ—ãƒª": "ä¸­å„ªå…ˆåº¦",
            "ã‚µã‚¤ãƒˆ": "ä½å„ªå…ˆåº¦",
            "ç®¡ç†": "ä½å„ªå…ˆåº¦",
            "ã‚³ãƒ³ã‚µãƒ«": "ä¸­å„ªå…ˆåº¦",
            "Ai": "è¶…é«˜å„ªå…ˆåº¦",
            "äººå·¥çŸ¥èƒ½": "é«˜å„ªå…ˆåº¦"
        }
        for keyword, priority in additional_keywords.items():
            if keyword.lower() in title_lower:
                matches.append({"skill": keyword, "priority": priority})
        seen_skills = set()
        unique_matches = []
        for m in matches:
            if m["skill"] not in seen_skills:
                unique_matches.append(m)
                seen_skills.add(m["skill"])
        return unique_matches

    def format_skill_matches(self, skill_matches):
        if not skill_matches:
            return "ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: ãªã—"
        skills_by_priority = {}
        for m in skill_matches:
            p = m["priority"]
            skills_by_priority.setdefault(p, []).append(m["skill"])
        parts = []
        if "è¶…é«˜å„ªå…ˆåº¦" in skills_by_priority: parts.append(f"ğŸ”¥{', '.join(skills_by_priority['è¶…é«˜å„ªå…ˆåº¦'])}")
        if "é«˜å„ªå…ˆåº¦" in skills_by_priority:  parts.append(f"â˜…{', '.join(skills_by_priority['é«˜å„ªå…ˆåº¦'])}")
        if "ä¸­å„ªå…ˆåº¦" in skills_by_priority:  parts.append(f"â—†{', '.join(skills_by_priority['ä¸­å„ªå…ˆåº¦'])}")
        if "ä½å„ªå…ˆåº¦" in skills_by_priority:  parts.append(f"â—‡{', '.join(skills_by_priority['ä½å„ªå…ˆåº¦'])}")
        if "æœ€ä½å„ªå…ˆåº¦" in skills_by_priority: parts.append(f"â—‹{', '.join(skills_by_priority['æœ€ä½å„ªå…ˆåº¦'])}")
        return f"ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: {' | '.join(parts)}" if parts else "ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: ãªã—"

    def format_skill_matches_compact(self, skill_matches: List[dict]) -> str:
        if not skill_matches:
            return "ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: ãªã—"
        ultra = [m.get("skill") for m in skill_matches if m.get("priority") == "è¶…é«˜å„ªå…ˆåº¦"]
        high  = [m.get("skill") for m in skill_matches if m.get("priority") == "é«˜å„ªå…ˆåº¦"]
        mid   = [m.get("skill") for m in skill_matches if m.get("priority") == "ä¸­å„ªå…ˆåº¦"]
        low   = [m.get("skill") for m in skill_matches if m.get("priority") == "ä½å„ªå…ˆåº¦"]
        lowst = [m.get("skill") for m in skill_matches if m.get("priority") == "æœ€ä½å„ªå…ˆåº¦"]
        parts = []
        if ultra: parts.append("ğŸ”¥" + ",".join(ultra[:2]))
        if high:  parts.append("â˜…" + ",".join(high[:2]))
        if mid:   parts.append("â—†" + ",".join(mid[:2]))
        if low:   parts.append("â—‡" + ",".join(low[:1]))
        if lowst: parts.append("â—‹" + ",".join(lowst[:1]))
        s = " ".join(parts) if parts else ""
        if len(s) > 100: s = s[:97] + "..."
        return f"ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: {s}" if s else "ğŸ”§ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: ãªã—"

    async def extract_recruitment_details(self, element):
        recruitment_info = {
            "price": "ä¾¡æ ¼æƒ…å ±ãªã—",
            "deadline": "æœŸé™æƒ…å ±ãªã—",
            "applicant_count": "0",
            "recruitment_count": "1",
            "client_name": "ä¾é ¼è€…æƒ…å ±ãªã—",
            "status": "å‹Ÿé›†ä¸­",
            "urgency": False,
            "category": "ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º"
        }
        try:
            parent = await element.evaluate_handle("el => el.closest('.c-media, .p-jobList__item, article, li')")
            if parent:
                price_elem = await parent.query_selector(".c-media__price, .price, .budget, [class*='price']")
                if price_elem:
                    price_text = await price_elem.text_content()
                    if price_text and "å††" in price_text:
                        recruitment_info["price"] = self.clean_price_text(price_text)
                deadline_elem = await parent.query_selector(".c-media__deadline, .deadline, [class*='deadline']")
                if deadline_elem:
                    deadline_text = await deadline_elem.text_content()
                    if deadline_text:
                        recruitment_info["deadline"] = deadline_text.strip()
                        if any(w in deadline_text for w in ["æ€¥å‹Ÿ", "ç·Šæ€¥", "å³æ—¥", "è‡³æ€¥"]):
                            recruitment_info["urgency"] = True
                applicant_elem = await parent.query_selector(".c-media__applicant, .applicant, [class*='applicant']")
                if applicant_elem:
                    applicant_text = await applicant_elem.text_content()
                    if applicant_text:
                        numbers = re.findall(r'(\d+)', applicant_text)
                        if len(numbers) >= 2:
                            recruitment_info["applicant_count"] = numbers[0]
                            recruitment_info["recruitment_count"] = numbers[1]
        except:
            pass
        return recruitment_info

    def clean_title(self, title):
        if not title:
            return ""
        try:
            import unicodedata
            title = unicodedata.normalize('NFKC', title)
        except:
            pass
        title = re.sub(r'\s+', ' ', title.strip())
        title = re.sub(r'^(NEW\s*){1,}', '', title, flags=re.IGNORECASE)
        title = re.sub(r'^\d+å›ç›®\s*', '', title)
        return title.strip()

    def clean_price_text(self, raw_price):
        if not raw_price:
            return "ä¾¡æ ¼æƒ…å ±ãªã—"
        try:
            import unicodedata
            raw_price = unicodedata.normalize('NFKC', raw_price)
        except:
            pass
        price = re.sub(r'\s+', ' ', raw_price.strip())
        price = re.sub(r'å††\s*/\s*', 'å†† / ', price)
        return price

    def calculate_comprehensive_score(self, title, recruitment_info, skill_matches):
        score = 0
        title_lower = title.lower()
        for m in skill_matches:
            p = m["priority"]
            if p == "è¶…é«˜å„ªå…ˆåº¦": score += 100
            elif p == "é«˜å„ªå…ˆåº¦": score += 50
            elif p == "ä¸­å„ªå…ˆåº¦": score += 20
            elif p == "ä½å„ªå…ˆåº¦": score += 10
            elif p == "æœ€ä½å„ªå…ˆåº¦": score += 5
        if len(skill_matches) >= 3: score += 50
        elif len(skill_matches) >= 2: score += 25
        elif len(skill_matches) >= 1: score += 10
        priority_keywords = {
            "chatgpt": 80, "python": 70, "api": 60, "ai": 60,
            "è‡ªå‹•åŒ–": 40, "bot": 40, "åŠ¹ç‡åŒ–": 30, "ãƒ„ãƒ¼ãƒ«": 25, "é–‹ç™º": 20, "ã‚·ã‚¹ãƒ†ãƒ ": 15
        }
        for k, bonus in priority_keywords.items():
            if k in title_lower:
                score += bonus
        if recruitment_info["urgency"]:
            score += 15
        try:
            applicant_count = int(recruitment_info["applicant_count"])
            if applicant_count == 0: score += 10
            elif applicant_count <= 2: score += 5
        except:
            pass
        price_text = recruitment_info["price"]
        if "å††" in price_text:
            numbers = re.findall(r'(\d+,?\d*)', price_text.replace(',', ''))
            if numbers:
                try:
                    max_price = max([int(num.replace(',', '')) for num in numbers])
                    if max_price >= 500000: score += 15
                    elif max_price >= 100000: score += 8
                    elif max_price >= 50000:  score += 3
                except:
                    pass
        return score

    def should_include_job_minimal(self, job_info):
        title = job_info["title"]
        if not title or len(title.strip()) < 5:
            return False
        title_lower = title.lower()
        for keyword in EXCLUDE_KEYWORDS:
            if keyword.lower() in title_lower:
                return False
        status = job_info["status"]
        if any(w in status for w in ["å‹Ÿé›†çµ‚äº†", "ç· åˆ‡", "çµ‚äº†", "å®Œäº†"]):
            return False
        if job_info["priority_score"] >= 10 or job_info["skill_count"] >= 1:
            return True
        priority_keywords = ["chatgpt", "python", "api", "ai", "è‡ªå‹•åŒ–", "bot", "åŠ¹ç‡åŒ–", "ãƒ„ãƒ¼ãƒ«", "é–‹ç™º", "ã‚·ã‚¹ãƒ†ãƒ "]
        if any(k in title_lower for k in priority_keywords):
            return True
        return False

    def sort_by_skill_relevance(self, jobs):
        def sort_key(job):
            base_score = job["priority_score"]
            if job["skill_count"] == 0:
                base_score -= 1000
            applicant_count = int(job["applicant_count"]) if job["applicant_count"].isdigit() else 999
            return (-base_score, -job["skill_count"], applicant_count, not job["urgency"], job["scraped_at"])
        return sorted(jobs, key=sort_key)

    def create_teams_payload(self, jobs):
        if not jobs:
            return {
                "@type": "MessageCard",
                "@context": "https://schema.org/extensions",
                "summary": "Lancerså…¨æ¡ˆä»¶é€šçŸ¥",
                "themeColor": "0078D4",
                "title": "ğŸš€ Lancerså…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆ",
                "text": "ğŸ“­ ç¾åœ¨æ¡ä»¶ã«åˆã†æ¡ˆä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            }
        MAX_CHARS = 25000
        header_text = f"ç¾åœ¨ã®å…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆã§ã™ï¼ˆ**{len(jobs)}ä»¶**ã‚’ç™ºè¦‹ï¼‰\n\n"
        footer_text = "\n\nğŸ“‹ è©³ç´°æƒ…å ±ã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚ç¢ºèªã§ãã¾ã™ã€‚"
        available_chars = MAX_CHARS - len(header_text) - len(footer_text) - 500
        main_content = ""
        displayed_count = 0
        skipped_count = 0
        print(f"ğŸ“Š Teamsè¡¨ç¤ºåˆ¶é™: {MAX_CHARS:,}æ–‡å­—ã¾ã§åˆ©ç”¨å¯èƒ½")
        for i, job in enumerate(jobs, 1):
            skill_info = self.format_skill_matches_compact(job["skill_matches"])
            job_text  = f"**{i}. {job['title']}**  \n"
            job_text += f"ğŸ’° {job['price']}  \n"
            if job['deadline'] != "æœŸé™æƒ…å ±ãªã—" and len(job['deadline']) < 20:
                job_text += f"â° {job['deadline']}  \n"
            if job['applicant_count'] != "0":
                job_text += f"ğŸ‘¥ å¿œå‹Ÿ{job['applicant_count']}äºº  \n"
            job_text += f"{skill_info}  \n"
            if job['urgency']:
                job_text += f"ğŸš¨ æ€¥å‹Ÿ  \n"
            job_text += f"ğŸ”— [è©³ç´°]({job['link']})  \n\n"
            if len(main_content) + len(job_text) > available_chars:
                skipped_count = len(jobs) - displayed_count
                print(f"ğŸ“ æ–‡å­—æ•°åˆ¶é™ã«ã‚ˆã‚Š {displayed_count}ä»¶è¡¨ç¤ºã€{skipped_count}ä»¶ã‚¹ã‚­ãƒƒãƒ—")
                break
            main_content += job_text
            displayed_count += 1
        final_text = header_text + main_content + (f"\nğŸ“‹ æ®‹ã‚Š{skipped_count}ä»¶ã®æ¡ˆä»¶ã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã§ç¢ºèªã§ãã¾ã™ã€‚" if skipped_count > 0 else footer_text)
        actual_chars = len(final_text)
        print(f"ğŸ“Š å®Ÿéš›ã®æ–‡å­—æ•°: {actual_chars:,}æ–‡å­— / {MAX_CHARS:,}æ–‡å­— ({actual_chars/MAX_CHARS*100:.1f}%)")
        print(f"ğŸ“Š è¡¨ç¤ºæ¡ˆä»¶æ•°: {displayed_count}ä»¶ / {len(jobs)}ä»¶")
        return {
            "@type": "MessageCard",
            "@context": "https://schema.org/extensions",
            "summary": f"Lancerså…¨æ¡ˆä»¶ {len(jobs)}ä»¶",
            "themeColor": "0078D4",
            "title": f"ğŸš€ Lancerså…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆ ({len(jobs)}ä»¶ç™ºè¦‹ / {displayed_count}ä»¶è¡¨ç¤º) - {datetime.now().strftime('%Y/%m/%d %H:%M')}",
            "text": final_text,
            "potentialAction": [{
                "@type": "OpenUri",
                "name": "ğŸ” Lancersã§æ¡ˆä»¶ã‚’æ¢ã™",
                "targets": [{"os": "default", "uri": LANCERS_SEARCH_URL}]
            }]
        }

    async def send_to_teams(self, jobs):
        try:
            from dotenv import load_dotenv
            load_dotenv()
        except:
            pass
        webhook_url = os.getenv("TEAMS_WEBHOOK_URL")
        if not webhook_url:
            print("âŒ Teams Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        payload = self.create_teams_payload(jobs)
        try:
            async with aiohttp.ClientSession() as session:
                print("ğŸ“¤ Teamsã«å…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
                async with session.post(
                    webhook_url,
                    json=payload,
                    headers={"Content-Type": "application/json"}
                ) as response:
                    if response.status == 200:
                        print("âœ… Teamsé€ä¿¡æˆåŠŸï¼")
                        return True
                    else:
                        print(f"âŒ Teamsé€ä¿¡å¤±æ•— (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status})")
                        return False
        except Exception as e:
            print(f"âŒ Teamsé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def save_data(self, jobs):
        timestamp = datetime.now()
        data = {
            "timestamp": timestamp.isoformat(),
            "count": len(jobs),
            "type": "å…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆ",
            "skill_summary": self.create_skill_summary(jobs),
            "skill_distribution": self.create_skill_distribution(jobs),
            "jobs": jobs
        }
        filename = f"all_jobs_{timestamp.strftime('%Y%m%d_%H%M')}.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å…¨æ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {filename}")

    def create_skill_summary(self, jobs):
        skill_counts = {}
        for job in jobs:
            for match in job["skill_matches"]:
                skill = match["skill"]
                skill_counts[skill] = skill_counts.get(skill, 0) + 1
        return dict(sorted(skill_counts.items(), key=lambda x: x[1], reverse=True))

    def create_skill_distribution(self, jobs):
        total_jobs = len(jobs)
        no_skill_jobs = len([job for job in jobs if job["skill_count"] == 0])
        multi_skill_jobs = len([job for job in jobs if job["skill_count"] >= 2])
        high_priority_jobs = len([job for job in jobs if job["priority_score"] >= 10])
        return {
            "total_jobs": total_jobs,
            "no_skill_match": no_skill_jobs,
            "multi_skill_match": multi_skill_jobs,
            "high_priority": high_priority_jobs,
            "skill_match_rate": round((total_jobs - no_skill_jobs) / total_jobs * 100, 1) if total_jobs > 0 else 0
        }
        

# =============================
# Excel ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# =============================
def clean_excel_data(excel_path: str = EXCEL_PATH):
    """Excelãƒ•ã‚¡ã‚¤ãƒ«å†…ã®é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã¨æœŸé™åˆ‡ã‚Œãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    try:
        path = Path(excel_path)
        if not path.exists():
            print("ğŸ“„ Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆåˆå›ãªã©ï¼‰")
            return

        wb = openpyxl.load_workbook(path)
        if "ãƒ©ãƒ³ã‚µãƒ¼ã‚º" not in wb.sheetnames:
            print("ğŸ“„ ãƒ©ãƒ³ã‚µãƒ¼ã‚ºã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return

        ws = wb["ãƒ©ãƒ³ã‚µãƒ¼ã‚º"]

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        all_rows = []
        for row_idx in range(2, ws.max_row + 1):
            row_data = []
            for col_idx in range(1, 9):  # 8åˆ—
                cell_value = ws.cell(row=row_idx, column=col_idx).value
                row_data.append(cell_value)
            if len(row_data) > 5 and row_data[5]:
                all_rows.append({
                    'row_index': row_idx,
                    'date': row_data[0],
                    'title': row_data[1],
                    'category': row_data[2],
                    'price': row_data[3],
                    'deadline': row_data[4],
                    'url': row_data[5],
                    'score': row_data[6] if len(row_data) > 6 else None,
                    'skills': row_data[7] if len(row_data) > 7 else None
                })

        print(f"ğŸ“Š å‡¦ç†å‰ã®ãƒ‡ãƒ¼ã‚¿æ•°: {len(all_rows)}ä»¶")

        # 1) URLé‡è¤‡ï¼ˆæ–°ã—ã„ã‚‚ã®ã‚’æ®‹ã™ï¼‰
        url_latest = {}
        for row in all_rows:
            url = row['url']
            if url not in url_latest:
                url_latest[url] = row
            else:
                try:
                    current_date = datetime.strptime(str(row['date']), "%Y-%m-%d %H:%M:%S")
                    existing_date = datetime.strptime(str(url_latest[url]['date']), "%Y-%m-%d %H:%M:%S")
                    if current_date > existing_date:
                        url_latest[url] = row
                except:
                    pass

        # 2) æœŸé™åˆ‡ã‚Œ/å¤ã„ãƒ‡ãƒ¼ã‚¿
        now = datetime.now()
        one_month_ago = now - timedelta(days=30)

        filtered_rows = []
        removed_count = {'duplicate': len(all_rows) - len(url_latest), 'expired': 0, 'old': 0}

        for url, row in url_latest.items():
            keep_row = True
            try:
                row_date = datetime.strptime(str(row['date']), "%Y-%m-%d %H:%M:%S")
                if row_date < one_month_ago:
                    keep_row = False
                    removed_count['old'] += 1
            except:
                pass

            if keep_row and row['deadline']:
                deadline_text = str(row['deadline'])
                if 'ç· åˆ‡' in deadline_text or 'çµ‚äº†' in deadline_text:
                    keep_row = False
                    removed_count['expired'] += 1
                else:
                    try:
                        deadline_date = None
                        date_match = re.search(r'(\d{4})[/-](\d{1,2})[/-](\d{1,2})', deadline_text)
                        if not date_match:
                            date_match = re.search(r'(\d{1,2})[/-](\d{1,2})', deadline_text)
                            if date_match:
                                month, day = int(date_match.group(1)), int(date_match.group(2))
                                year = now.year
                                deadline_date = datetime(year, month, day)
                            else:
                                date_match = re.search(r'(\d{1,2})æœˆ(\d{1,2})æ—¥', deadline_text)
                                if date_match:
                                    month, day = int(date_match.group(1)), int(date_match.group(2))
                                    year = now.year
                                    deadline_date = datetime(year, month, day)
                        else:
                            year, month, day = int(date_match.group(1)), int(date_match.group(2)), int(date_match.group(3))
                            deadline_date = datetime(year, month, day)

                        if deadline_date and deadline_date < now:
                            keep_row = False
                            removed_count['expired'] += 1
                    except:
                        pass

            if keep_row:
                filtered_rows.append(row)

        print(f"ğŸ—‘ï¸ å‰Šé™¤ãƒ‡ãƒ¼ã‚¿: é‡è¤‡ {removed_count['duplicate']} / 1ãƒ¶æœˆä»¥ä¸Šå‰ {removed_count['old']} / æœŸé™åˆ‡ã‚Œ {removed_count['expired']}")
        print(f"ğŸ“Š å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿æ•°: {len(filtered_rows)}ä»¶")

        # å†ä½œæˆ
        wb.remove(ws)
        ws = wb.create_sheet("ãƒ©ãƒ³ã‚µãƒ¼ã‚º", 0)
        ws.append(["å–å¾—æ—¥æ™‚","ã‚¿ã‚¤ãƒˆãƒ«","ã‚«ãƒ†ã‚´ãƒª","ä¾¡æ ¼","ç· åˆ‡","URL","å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢","ã‚¹ã‚­ãƒ«æ¦‚è¦"])

        for row in sorted(filtered_rows, key=lambda x: str(x['date']), reverse=True):
            ws.append([row['date'], row['title'], row['category'], row['price'], row['deadline'], row['url'], row['score'], row['skills']])
            last = ws.max_row
            if row['url']:
                try:
                    ws.cell(row=last, column=6).hyperlink = row['url']
                    ws.cell(row=last, column=6).style = "Hyperlink"
                except:
                    pass

        _autosize_columns(ws)
        wb.save(path)
        print(f"âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†: {path}")

        return {'before': len(all_rows), 'after': len(filtered_rows), 'removed': removed_count}

    except Exception as e:
        print(f"âŒ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

# =============================
# ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# =============================
async def main():
    print("=" * 70)
    print("ğŸ¤– Lancerså…¨æ¡ˆä»¶å–å¾—ã‚·ã‚¹ãƒ†ãƒ ï¼ˆTeams28KBæœ€å¤§æ´»ç”¨ç‰ˆï¼‰")
    print("=" * 70)

    print("\nğŸ“§ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
    clean_result = clean_excel_data(EXCEL_PATH)
    if clean_result:
        print(f"   å‡¦ç†å‰: {clean_result['before']}ä»¶ â†’ å‡¦ç†å¾Œ: {clean_result['after']}ä»¶")

    # ...ç¶šãå‡¦ç†ã‚‚ã™ã¹ã¦ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã—ã¦ãŠãã“ã¨...

    notifier = CompleteJobsNotifier()
    jobs = await notifier.fetch_jobs()

    if jobs:
        # JSONä¿å­˜ï¼ˆãƒªãƒã‚¸ãƒˆãƒª or ãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
        notifier.save_data(jobs)

        # ğŸ”§ ã“ã“ã§å…ˆã«å®šç¾©ã™ã‚‹ï¼
        excel_data = {
            "timestamp": datetime.now().isoformat(),
            "count": len(jobs),
            "type": "å…¨æ¡ˆä»¶ãƒªã‚¹ãƒˆ",
            "skill_summary": notifier.create_skill_summary(jobs),
            "skill_distribution": notifier.create_skill_distribution(jobs),
            "jobs": jobs
        }

        # Excelã®ã€Œãƒ©ãƒ³ã‚µãƒ¼ã‚ºã€ã‚·ãƒ¼ãƒˆã‚’ä¸Šæ›¸ã
        replace_lancers_sheet(excel_data, EXCEL_PATH)

        # è¿½è¨˜å¾Œã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        print("\nğŸ“§ è¿½è¨˜å¾Œã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°...")
        clean_excel_data(EXCEL_PATH)

        # Teamsé€ä¿¡
        teams_success = await notifier.send_to_teams(jobs)

        print("\n" + "=" * 70)
        print("ğŸ“Š å®Ÿè¡Œçµæœ:")
        print("=" * 70)
        print(f"âœ… å…¨æ¡ˆä»¶æ•°: {len(jobs)}ä»¶")
        print(f"ğŸ“¤ Teamsé€ä¿¡: {'æˆåŠŸ' if teams_success else 'å¤±æ•—'}")
        print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜: å®Œäº†")

        skill_summary = notifier.create_skill_summary(jobs)
        skill_distribution = notifier.create_skill_distribution(jobs)
        print(f"\nğŸ”§ ã‚¹ã‚­ãƒ«åˆ¥ãƒãƒƒãƒä»¶æ•°ï¼ˆä¸Šä½10ä½ï¼‰:")
        for skill, count in list(skill_summary.items())[:10]:
            print(f"   {skill}: {count}ä»¶")

        print(f"\nğŸ“ˆ ã‚¹ã‚­ãƒ«åˆ†å¸ƒ:")
        print(f"   ã‚¹ã‚­ãƒ«ãƒãƒƒãƒç‡: {skill_distribution['skill_match_rate']}%")
        print(f"   è¤‡æ•°ã‚¹ã‚­ãƒ«ãƒãƒƒãƒ: {skill_distribution['multi_skill_match']}ä»¶")
        print(f"   é«˜å„ªå…ˆåº¦æ¡ˆä»¶: {skill_distribution['high_priority']}ä»¶")
        print(f"   ã‚¹ã‚­ãƒ«ãƒãƒƒãƒãªã—: {skill_distribution['no_skill_match']}ä»¶")
    else:
        print("âŒ æ¡ˆä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    asyncio.run(main())
